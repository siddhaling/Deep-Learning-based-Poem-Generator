{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Poem Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSAY0xnWIOQX"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST6uurztPurq"
      },
      "source": [
        "path = \"path-to-dataset\"\n",
        "poems_data = open(path, \"r\").read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWuvrpSXJFMG"
      },
      "source": [
        "data_corpus = poems_data.lower().split(\"\\n\")\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data_corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "#print(data_corpus)\n",
        "#print(tokenizer.word_index)\n",
        "#print(total_words)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qFce2xHJTvV"
      },
      "source": [
        "# create input sequences using list of tokens\n",
        "input_seqs = []\n",
        "for line in data_corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_seqs = token_list[:i+1]\n",
        "\t\tinput_seqs.append(n_gram_seqs)\n",
        "\n",
        "# pad sequences \n",
        "max_seqs_len = max([len(x) for x in input_seqs])\n",
        "input_seqs = np.array(pad_sequences(input_seqs, maxlen=max_seqs_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "preds, labels = input_seqs[:,:-1],input_seqs[:,-1]\n",
        "\n",
        "labels = ku.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G711s4ehKG9G",
        "outputId": "82ecb9a4-311e-4393-9ef7-c13ded9d8363"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_seqs_len - 1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer= 'RMSprop',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 22, 100)           238000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 22, 300)          301200    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 22, 300)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               160400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1190)              120190    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2380)              2834580   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,654,370\n",
            "Trainable params: 3,654,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3EDk_-CQGC-"
      },
      "source": [
        "import os\n",
        "checkpoint_path = \"your-directory-path/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvNI17BZKUMR",
        "outputId": "8f356baa-b714-475e-b771-cc7ed794dd63"
      },
      "source": [
        "import os\n",
        "checkpoint_path = \"your-directory-path/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f262f469250>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbv_SCJEKW0g"
      },
      "source": [
        "model_history = model.fit(preds, labels, epochs=250, verbose=1, callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul7QErSlKs3Q"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model_acc = model_history.history['accuracy']\n",
        "model_loss = model_history.history['loss']\n",
        "\n",
        "\n",
        "nepochs = range(len(model_acc))\n",
        "\n",
        "plt.plot(nepochs, model_acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(nepochs, model_loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQkIu-uiLJkY",
        "outputId": "7ea4a573-bbde-452e-9791-ba12130e3bdf"
      },
      "source": [
        "start_txt = \"the weather is nice\"\n",
        "nwords = 110\n",
        "  \n",
        "for _ in range(nwords):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([start_txt])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_seqs_len-1, padding='pre')\n",
        "\tpredicted_word = np.argmax(model.predict(token_list, verbose=0))\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted_word:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tstart_txt += \" \" + output_word\n",
        "\n",
        "start_txt = start_txt.split()\n",
        "n = 6\n",
        "[' '.join(start_txt[i:i+n]) for i in range(0,len(start_txt),n)]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the weather is nice glee done',\n",
              " 'mirth out out like furnace for',\n",
              " 'fine plashless was no mouth up',\n",
              " 'with her fearful storm have come',\n",
              " 'was ever gloom their comet down',\n",
              " 'the snow to fatal song enough',\n",
              " \"an england's worm her door is\",\n",
              " 'year or road over night i',\n",
              " 'those for this forests and her',\n",
              " 'mouth and like what a thoughts',\n",
              " 'in the hour everything cottage grieve',\n",
              " 'happen mildly simple the bay lash',\n",
              " 'the a a thoughts of the',\n",
              " 'a is forget a is she',\n",
              " 'sound’s the road up was those',\n",
              " 'who once it dreams in he',\n",
              " 'know love anyway throw their hair',\n",
              " 'lives express rooms climb on your',\n",
              " 'work and shot who see my']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YALe5kULL05L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}